{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 18:35:49.234616: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-30 18:35:49.245218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735580149.256905    4615 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735580149.260466    4615 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-30 18:35:49.273925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "#!pip install -r /work/NLP_IMDb_Exam/requirements.txt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "import evaluate\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict= {\n",
    "    1 :{\n",
    "        \"name\" : \"MiniLM_L6\",\n",
    "        \"huggingface\" : \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        },\n",
    "\n",
    "    2 :{\n",
    "        \"name\" : \"MPNET_base\",\n",
    "        \"huggingface\" : 'sentence-transformers/all-mpnet-base-v2',\n",
    "        },    \n",
    "\n",
    "    3 :{\n",
    "        \"name\" : \"Instructor\",\n",
    "        \"huggingface\" : \"hkunlp/instructor-large\",\n",
    "    },}\n",
    "\n",
    "rating_type={\n",
    "    1 : \"average_rating\",\n",
    "    2 : \"rating\",\n",
    "}\n",
    "\n",
    "\n",
    "# Choose a model for a pseudo-function\n",
    "Chosen_Model= 2\n",
    "Rating_to_Drop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000947</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.074283</td>\n",
       "      <td>-0.039043</td>\n",
       "      <td>-0.032846</td>\n",
       "      <td>-0.052571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017689</td>\n",
       "      <td>-0.084283</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.043206</td>\n",
       "      <td>-0.031605</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.031745</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052814</td>\n",
       "      <td>0.075769</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>-0.067636</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>-0.012041</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.021684</td>\n",
       "      <td>-0.033824</td>\n",
       "      <td>-0.027393</td>\n",
       "      <td>-0.003892</td>\n",
       "      <td>0.050564</td>\n",
       "      <td>-0.012418</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009295</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>-0.008366</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>-0.024467</td>\n",
       "      <td>-0.058873</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>-0.079699</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.063945</td>\n",
       "      <td>-0.006870</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>-0.007758</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013212</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>-0.017202</td>\n",
       "      <td>0.064402</td>\n",
       "      <td>-0.022100</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>-0.038482</td>\n",
       "      <td>-0.045942</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>-0.055245</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>-0.046693</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.028939</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>-0.025342</td>\n",
       "      <td>0.028730</td>\n",
       "      <td>-0.047887</td>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>-0.012371</td>\n",
       "      <td>-0.023801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013046</td>\n",
       "      <td>-0.054086</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.079416</td>\n",
       "      <td>-0.028491</td>\n",
       "      <td>0.051881</td>\n",
       "      <td>-0.015033</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.053012</td>\n",
       "      <td>-0.032119</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.025475</td>\n",
       "      <td>-0.019095</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>0.030446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050177</td>\n",
       "      <td>-0.005847</td>\n",
       "      <td>-0.019756</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.033641</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>-0.020493</td>\n",
       "      <td>-0.026690</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-0.015336</td>\n",
       "      <td>-0.002935</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.042267</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>-0.054165</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.031114</td>\n",
       "      <td>-0.030957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>-0.039896</td>\n",
       "      <td>-0.019493</td>\n",
       "      <td>-0.024774</td>\n",
       "      <td>-0.043664</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-0.012683</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>-0.057868</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.013149</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>-0.113928</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042010</td>\n",
       "      <td>-0.067297</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>-0.004276</td>\n",
       "      <td>-0.066133</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>-0.009513</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-0.036789</td>\n",
       "      <td>-0.032421</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>0.029219</td>\n",
       "      <td>-0.119113</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024835</td>\n",
       "      <td>0.073117</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.011802</td>\n",
       "      <td>0.027796</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>-0.010568</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-0.035967</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.022708</td>\n",
       "      <td>-0.016076</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>-0.041813</td>\n",
       "      <td>0.025491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>-0.009835</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.044546</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.000947  0.012226  0.007005  0.055534 -0.014657  0.002093 -0.074283   \n",
       "1     -0.052814  0.075769 -0.001993  0.000877 -0.011637  0.033047 -0.067636   \n",
       "2      0.009295  0.026960 -0.008366  0.004835 -0.004934  0.028715 -0.028778   \n",
       "3      0.013212 -0.013945  0.020238 -0.017202  0.064402 -0.022100  0.005692   \n",
       "4      0.017525  0.003245 -0.025342  0.028730 -0.047887  0.027611  0.001204   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  0.010382  0.053012 -0.032119  0.057019  0.025475 -0.019095  0.019149   \n",
       "99996 -0.015336 -0.002935 -0.000669 -0.000911 -0.042267  0.010768 -0.054165   \n",
       "99997 -0.012683  0.065704 -0.005387  0.006981 -0.057868  0.001411 -0.013149   \n",
       "99998 -0.036789 -0.032421  0.001179  0.038486 -0.001766  0.029219 -0.119113   \n",
       "99999 -0.035967  0.003630 -0.005250 -0.022708 -0.016076  0.021322 -0.059975   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "0     -0.039043 -0.032846 -0.052571  ... -0.017689 -0.084283  0.017695   \n",
       "1      0.008955 -0.012041  0.013748  ... -0.019201  0.009876  0.021684   \n",
       "2     -0.024467 -0.058873  0.007024  ...  0.013301 -0.079699  0.032424   \n",
       "3     -0.038482 -0.045942 -0.008018  ...  0.060098 -0.055245 -0.005580   \n",
       "4      0.022175 -0.012371 -0.023801  ... -0.013046 -0.054086  0.037302   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99995  0.024946  0.026985  0.030446  ...  0.050177 -0.005847 -0.019756   \n",
       "99996  0.000786 -0.031114 -0.030957  ...  0.043812 -0.039896 -0.019493   \n",
       "99997  0.002003 -0.113928  0.008597  ...  0.042010 -0.067297 -0.011826   \n",
       "99998 -0.010546  0.012335  0.051544  ... -0.024835  0.073117  0.004253   \n",
       "99999  0.013485 -0.041813  0.025491  ...  0.043387  0.005910 -0.009835   \n",
       "\n",
       "            762       763       764       765       766       767  rating  \n",
       "0      0.004549  0.043206 -0.031605  0.011563  0.031745  0.002231       8  \n",
       "1     -0.033824 -0.027393 -0.003892  0.050564 -0.012418  0.008505       9  \n",
       "2     -0.007187  0.063945 -0.006870  0.012035  0.040202 -0.007758       3  \n",
       "3      0.001606 -0.046693  0.006035  0.012392  0.028939  0.009629       9  \n",
       "4      0.000146 -0.001943 -0.079416 -0.028491  0.051881 -0.015033      10  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "99995 -0.009247 -0.033641  0.019529 -0.020493 -0.026690  0.000773       1  \n",
       "99996 -0.024774 -0.043664 -0.004756  0.036723  0.051980  0.003448      10  \n",
       "99997 -0.004276 -0.066133  0.005304  0.036001  0.012250 -0.009513      10  \n",
       "99998 -0.016748 -0.011802  0.027796  0.040786 -0.010568  0.002672      10  \n",
       "99999 -0.000467  0.011965  0.032836  0.036593  0.044546  0.016421       9  \n",
       "\n",
       "[100000 rows x 769 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read embeddings from CSV \n",
    "#Base \n",
    "data_path= f'../Data/{model_dict[Chosen_Model][\"name\"]}/{model_dict[Chosen_Model][\"name\"]}.csv'\n",
    "Embeddings= pd.read_csv(data_path)\n",
    "Reviews= Embeddings['review']\n",
    "Embeddings= Embeddings.drop(columns=[rating_type[Rating_to_Drop], 'review'])\n",
    "model_dict[Chosen_Model]['Embeddings'] = Embeddings\n",
    "model_dict[Chosen_Model]['Embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_to_negative_vector(Positive, Negative):\n",
    "    \"\"\"\n",
    "    Takes a positive and an negative data point and defines the vector spanning both vectors.\n",
    "    \"\"\"\n",
    "    posneg_vector = Positive.mean().to_frame().T-Negative.mean().to_frame().T\n",
    "    posneg_vector = pd.DataFrame(posneg_vector)\n",
    "    return posneg_vector\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Old_Texts = np.array([\n",
    "    \"That is ancient!\",\n",
    "    \"This house was build in 1933\",\n",
    "    \"The past\",\n",
    "    \"Before the beginning\"\n",
    "])\n",
    "\n",
    "New_Texts = np.array([\n",
    "    \"This is very new\",\n",
    "    \"Very modern architechture is used for building this house\",\n",
    "    \"The present is now\",\n",
    "    \"The future\",\n",
    "    \"In the year of 2024\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Old_Texts = np.array([\n",
    "    \"This film redefines the action genre, delivering heart-pounding sequences and jaw-dropping stunts. A must-watch for adrenaline junkies!\",\n",
    "    \"A deeply moving tale that tugs at the heartstrings and leaves you with a renewed sense of hope. Truly unforgettable.\",\n",
    "    \"The visual effects are nothing short of breathtaking. Every frame is a work of art that immerses you completely.\",\n",
    "    \"The cast's chemistry and brilliant performances bring the story to life in the most authentic and engaging way.\",\n",
    "    \"A cinematic masterpiece with impeccable direction that seamlessly blends drama, suspense, and emotion.\",\n",
    "    \"The characters are so well-developed and relatable that you can't help but get invested in their journey.\",\n",
    "    \"An absolute laugh riot from start to finish! The witty dialogue and hilarious antics are sure to leave you in stitches.\",\n",
    "    \"The world-building in this movie is unparalleled. Every detail is carefully crafted, creating a universe you'll never want to leave.\",\n",
    "    \"A powerful and inspiring story that leaves you motivated to chase your dreams and overcome any obstacles.\",\n",
    "    \"The music complements the story beautifully, elevating emotional moments and adding depth to every scene.\",\n",
    "    \"This movie keeps you on the edge of your seat with its clever twists and turns. A gripping ride you won't forget.\",\n",
    "    \"A refreshing take on a familiar theme, offering a perspective that feels both innovative and deeply resonant.\",\n",
    "    \"Perfect for audiences of all ages, this movie delivers laughter, lessons, and love in equal measure.\",\n",
    "    \"The cinematography is a visual feast, capturing both the grandeur of the setting and the intimacy of the characters' emotions.\",\n",
    "    \"A delightful story that warms your heart and reminds you of the simple joys in life.\",\n",
    "    \"An exhilarating journey filled with excitement, danger, and triumph. An epic adventure for the ages.\",\n",
    "    \"The actors' raw and genuine performances make you forget you're watching a movie. Pure artistry.\",\n",
    "    \"This film masterfully combines humor, drama, and action, making it a rollercoaster of emotions from start to finish.\",\n",
    "    \"A vibrant celebration of culture and tradition, beautifully portrayed with authenticity and reverence.\",\n",
    "    \"A film that transcends time with its universal themes and captivating storytelling. Destined to become a classic.\"\n",
    "])\n",
    "\n",
    "New_Texts = np.array([\n",
    "    \"This movie lacks any sense of direction, leaving the audience confused and frustrated.\",\n",
    "    \"The storyline is painfully predictable, offering nothing new or exciting.\",\n",
    "    \"Poorly written characters make it impossible to care about what happens to them.\",\n",
    "    \"The acting is wooden and emotionless, making every scene feel forced and lifeless.\",\n",
    "    \"A complete waste of stunning visuals due to a hollow and uninspired plot.\",\n",
    "    \"The humor feels forced and falls flat, making the comedy aspect unbearable.\",\n",
    "    \"Pacing issues plague the movie, with some parts dragging endlessly while others feel rushed.\",\n",
    "    \"The dialogue is cringeworthy and unnatural, detracting from the overall experience.\",\n",
    "    \"A disappointing sequel that fails to capture the magic of the original.\",\n",
    "    \"The special effects are overused, overshadowing the weak storytelling.\",\n",
    "    \"This movie tries too hard to be edgy but ends up being obnoxious and shallow.\",\n",
    "    \"The soundtrack is forgettable and adds no value to the film.\",\n",
    "    \"An overstuffed plot with too many subplots that go nowhere.\",\n",
    "    \"The lack of chemistry between the leads makes their relationship unconvincing.\",\n",
    "    \"The ending is abrupt and unsatisfying, leaving more questions than answers.\",\n",
    "    \"An unoriginal rehash of better films, lacking any creativity or fresh ideas.\",\n",
    "    \"The movie’s tone is inconsistent, making it hard to take seriously.\",\n",
    "    \"Unnecessarily long runtime with scenes that add nothing to the story.\",\n",
    "    \"The action sequences are chaotic and poorly choreographed, making them hard to follow.\",\n",
    "    \"An underwhelming experience that fails to leave any lasting impression.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Old_Texts = np.array([\n",
    "    \"An old movie\",\n",
    "\n",
    "])\n",
    "\n",
    "New_Texts = np.array([\n",
    "    \"A new movie\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.014276</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>-0.005599</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>-0.045776</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>-0.006239</td>\n",
       "      <td>-0.033217</td>\n",
       "      <td>-0.023729</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05813</td>\n",
       "      <td>-0.013627</td>\n",
       "      <td>-0.024711</td>\n",
       "      <td>-0.021215</td>\n",
       "      <td>-0.00582</td>\n",
       "      <td>-0.033011</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>-0.021013</td>\n",
       "      <td>-0.012745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.014276  0.013795 -0.005599 -0.025262 -0.045776 -0.039191 -0.006239   \n",
       "\n",
       "        7         8         9    ...      758       759       760       761  \\\n",
       "0 -0.033217 -0.023729  0.002896  ...  0.05813 -0.013627 -0.024711 -0.021215   \n",
       "\n",
       "       762       763       764       765       766       767  \n",
       "0 -0.00582 -0.033011  0.028346  0.017474 -0.021013 -0.012745  \n",
       "\n",
       "[1 rows x 768 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model = SentenceTransformer(model_dict[Chosen_Model][\"huggingface\"], device=\"cuda\") # Choose the best sentence transformer according to https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "Old_Embeddings = pd.DataFrame(transformer_model.encode(Old_Texts))\n",
    "New_Embeddings = pd.DataFrame(transformer_model.encode(New_Texts))\n",
    "Time_Vec= positive_to_negative_vector(Positive= New_Embeddings, Negative= Old_Embeddings)\n",
    "Time_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_matrix_to_vector(matrix, vector):\n",
    "    \"\"\"Compute the projection of a matrix onto the space spanned by the vector\n",
    "    Args:\n",
    "        vector: ndarray of dimension (D, 1), the vector spanning D dimensions that you want to project upon.\n",
    "        matrix: ndarray of dimension (D, M), the matrix consisting of M vectors that you want to map to the subspace spanned by the vector.\n",
    "    \n",
    "    Returns:\n",
    "        p: projection of matrix onto the subspac spanned by the columns of vector; size (D, 1)\n",
    "    \"\"\"\n",
    "    m = matrix.to_numpy() # Turn into a matrix\n",
    "    v = vector.to_numpy()[0] #Turn into a numpy array\n",
    "\n",
    "    # Compute v dot v (denominator)\n",
    "    v_dot_v = np.dot(v, v)\n",
    "\n",
    "    # Compute projection of each row of m onto v\n",
    "    projection = np.outer(np.dot(m, v) / v_dot_v, v)\n",
    "    projection = pd.DataFrame(projection)\n",
    "\n",
    "    return projection\n",
    "def express_matrix_by_vector(matrix, vector):\n",
    "    \"\"\"Compute the projection of a matrix onto the space spanned by the vector\n",
    "    Args:\n",
    "        vector: ndarray of dimension (D, 1), the vector spanning D dimensions that you want to project upon.\n",
    "        matrix: ndarray of dimension (D, M), the matrix consisting of M vectors that you want to map to the subspace spanned by the vector.\n",
    "    \n",
    "    Returns:\n",
    "        projection: projection of matrix onto the subspac spanned by the columns of vector; size (D, 1)\n",
    "        projection_in_1D_subspace: Each embedding projected onto 1 dimensional subspace spanned by input vector.\n",
    "    \"\"\"\n",
    "    unit_vector = vector / np.linalg.norm(vector) # Find the unit vector for interpretatbility by dividing with its norm\n",
    "    projection = project_matrix_to_vector(matrix, vector) # Find projections, so we can find lengths by finding relations in first dimension\n",
    "    projection_in_1D_subspace = projection.iloc[:,0]/unit_vector.iloc[:,0][0] # Location in subspace\n",
    "\n",
    "    return projection, projection_in_1D_subspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000947</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.074283</td>\n",
       "      <td>-0.039043</td>\n",
       "      <td>-0.032846</td>\n",
       "      <td>-0.052571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060012</td>\n",
       "      <td>-0.017689</td>\n",
       "      <td>-0.084283</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.043206</td>\n",
       "      <td>-0.031605</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.031745</td>\n",
       "      <td>0.002231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052814</td>\n",
       "      <td>0.075769</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>-0.067636</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>-0.012041</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.021684</td>\n",
       "      <td>-0.033824</td>\n",
       "      <td>-0.027393</td>\n",
       "      <td>-0.003892</td>\n",
       "      <td>0.050564</td>\n",
       "      <td>-0.012418</td>\n",
       "      <td>0.008505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009295</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>-0.008366</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>-0.024467</td>\n",
       "      <td>-0.058873</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073719</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>-0.079699</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.063945</td>\n",
       "      <td>-0.006870</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>-0.007758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013212</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>-0.017202</td>\n",
       "      <td>0.064402</td>\n",
       "      <td>-0.022100</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>-0.038482</td>\n",
       "      <td>-0.045942</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>-0.055245</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>-0.046693</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.028939</td>\n",
       "      <td>0.009629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>-0.025342</td>\n",
       "      <td>0.028730</td>\n",
       "      <td>-0.047887</td>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>-0.012371</td>\n",
       "      <td>-0.023801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042005</td>\n",
       "      <td>-0.013046</td>\n",
       "      <td>-0.054086</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.079416</td>\n",
       "      <td>-0.028491</td>\n",
       "      <td>0.051881</td>\n",
       "      <td>-0.015033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.053012</td>\n",
       "      <td>-0.032119</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.025475</td>\n",
       "      <td>-0.019095</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>0.030446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.050177</td>\n",
       "      <td>-0.005847</td>\n",
       "      <td>-0.019756</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.033641</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>-0.020493</td>\n",
       "      <td>-0.026690</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-0.015336</td>\n",
       "      <td>-0.002935</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.042267</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>-0.054165</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.031114</td>\n",
       "      <td>-0.030957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030846</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>-0.039896</td>\n",
       "      <td>-0.019493</td>\n",
       "      <td>-0.024774</td>\n",
       "      <td>-0.043664</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-0.012683</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>-0.057868</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.013149</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>-0.113928</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.042010</td>\n",
       "      <td>-0.067297</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>-0.004276</td>\n",
       "      <td>-0.066133</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>-0.009513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-0.036789</td>\n",
       "      <td>-0.032421</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>0.029219</td>\n",
       "      <td>-0.119113</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>-0.024835</td>\n",
       "      <td>0.073117</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.011802</td>\n",
       "      <td>0.027796</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>-0.010568</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-0.035967</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>-0.022708</td>\n",
       "      <td>-0.016076</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>-0.041813</td>\n",
       "      <td>0.025491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022742</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>-0.009835</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.044546</td>\n",
       "      <td>0.016421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.000947  0.012226  0.007005  0.055534 -0.014657  0.002093 -0.074283   \n",
       "1     -0.052814  0.075769 -0.001993  0.000877 -0.011637  0.033047 -0.067636   \n",
       "2      0.009295  0.026960 -0.008366  0.004835 -0.004934  0.028715 -0.028778   \n",
       "3      0.013212 -0.013945  0.020238 -0.017202  0.064402 -0.022100  0.005692   \n",
       "4      0.017525  0.003245 -0.025342  0.028730 -0.047887  0.027611  0.001204   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  0.010382  0.053012 -0.032119  0.057019  0.025475 -0.019095  0.019149   \n",
       "99996 -0.015336 -0.002935 -0.000669 -0.000911 -0.042267  0.010768 -0.054165   \n",
       "99997 -0.012683  0.065704 -0.005387  0.006981 -0.057868  0.001411 -0.013149   \n",
       "99998 -0.036789 -0.032421  0.001179  0.038486 -0.001766  0.029219 -0.119113   \n",
       "99999 -0.035967  0.003630 -0.005250 -0.022708 -0.016076  0.021322 -0.059975   \n",
       "\n",
       "              7         8         9  ...       758       759       760  \\\n",
       "0     -0.039043 -0.032846 -0.052571  ... -0.060012 -0.017689 -0.084283   \n",
       "1      0.008955 -0.012041  0.013748  ... -0.010560 -0.019201  0.009876   \n",
       "2     -0.024467 -0.058873  0.007024  ... -0.073719  0.013301 -0.079699   \n",
       "3     -0.038482 -0.045942 -0.008018  ...  0.012678  0.060098 -0.055245   \n",
       "4      0.022175 -0.012371 -0.023801  ... -0.042005 -0.013046 -0.054086   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99995  0.024946  0.026985  0.030446  ...  0.058617  0.050177 -0.005847   \n",
       "99996  0.000786 -0.031114 -0.030957  ...  0.030846  0.043812 -0.039896   \n",
       "99997  0.002003 -0.113928  0.008597  ... -0.000142  0.042010 -0.067297   \n",
       "99998 -0.010546  0.012335  0.051544  ... -0.010776 -0.024835  0.073117   \n",
       "99999  0.013485 -0.041813  0.025491  ... -0.022742  0.043387  0.005910   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0      0.017695  0.004549  0.043206 -0.031605  0.011563  0.031745  0.002231  \n",
       "1      0.021684 -0.033824 -0.027393 -0.003892  0.050564 -0.012418  0.008505  \n",
       "2      0.032424 -0.007187  0.063945 -0.006870  0.012035  0.040202 -0.007758  \n",
       "3     -0.005580  0.001606 -0.046693  0.006035  0.012392  0.028939  0.009629  \n",
       "4      0.037302  0.000146 -0.001943 -0.079416 -0.028491  0.051881 -0.015033  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "99995 -0.019756 -0.009247 -0.033641  0.019529 -0.020493 -0.026690  0.000773  \n",
       "99996 -0.019493 -0.024774 -0.043664 -0.004756  0.036723  0.051980  0.003448  \n",
       "99997 -0.011826 -0.004276 -0.066133  0.005304  0.036001  0.012250 -0.009513  \n",
       "99998  0.004253 -0.016748 -0.011802  0.027796  0.040786 -0.010568  0.002672  \n",
       "99999 -0.009835 -0.000467  0.011965  0.032836  0.036593  0.044546  0.016421  \n",
       "\n",
       "[100000 rows x 768 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[Chosen_Model]['Embeddings'].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save positive negative corrected embedding:\n",
    "projected_variance, projection_in_1D_subspace = express_matrix_by_vector(matrix=model_dict[Chosen_Model]['Embeddings'].iloc[:,:-1], vector=Time_Vec)\n",
    "### \n",
    "time_corrected_embeddings = pd.DataFrame(model_dict[Chosen_Model]['Embeddings'].iloc[:,:-1].to_numpy()-projected_variance.to_numpy())\n",
    "time_corrected_embeddings['time_subspace'] = projection_in_1D_subspace\n",
    "time_corrected_embeddings['rating'] = model_dict[Chosen_Model]['Embeddings']['rating']\n",
    "save_corrected = f'../Data/time_corrected.csv'\n",
    "time_corrected_embeddings.to_csv(save_corrected, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_for_training(dataframe):\n",
    "    \"\"\"Prepare dataframe for regression\n",
    "    Args:\n",
    "        dataframe: pandas dataframe (D, M), the matrix consisting of D-1 independent variable, for M datapoints, and the dataframe.iloc[:,-1] is the dependent variable.\n",
    "    \n",
    "    Returns:\n",
    "        train_features: ndarray of independent training features\n",
    "        train_labels: ndarray of dependent variable for training \n",
    "        eval_features: ndarray of independent evaluation features\n",
    "        eval_labels: ndarray of dependent variable for training \n",
    "    \"\"\"\n",
    "    split = train_test_split(dataframe, train_size=0.7)\n",
    "    finaleval=split[1]\n",
    "    subset=split[0]\n",
    "\n",
    "    train_features = subset.iloc[:,0:-1].to_numpy()\n",
    "    train_labels = np.float32(subset.iloc[:,-1:].to_numpy())\n",
    "    eval_features = finaleval.iloc[:,0:-1].to_numpy()\n",
    "    eval_labels = np.float32(finaleval.iloc[:,-1:].to_numpy())\n",
    "\n",
    "    return train_features, train_labels, eval_features, eval_labels\n",
    "\n",
    "def linear_regression(train_features, train_labels, eval_features, eval_labels):\n",
    "    \"\"\"\n",
    "    Perform regression and return results, summary, and model.\n",
    "\n",
    "    Args:\n",
    "        train_features: ndarray of independent training features\n",
    "        train_labels: ndarray of dependent variable for training \n",
    "        eval_features: ndarray of independent evaluation features\n",
    "        eval_labels: ndarray of dependent variable for training \n",
    "\n",
    "    Returns:\n",
    "        results: DataFrame containing True and Predicted Labels\n",
    "        summary: Dictionary containing R-squared, MSE, Correlation\n",
    "        model: The trained regression model\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Regression Model\n",
    "    X = sm.add_constant(train_features)  # adding a constant\n",
    "    model = sm.OLS(train_labels, X).fit()\n",
    "\n",
    "    # Predictive accuracy\n",
    "    X_test = sm.add_constant(eval_features)  # add intercept to test_data\n",
    "    predictions = model.predict(X_test)  # predict\n",
    "\n",
    "    # Flatten eval_labels if necessary\n",
    "    eval_labels = eval_labels.ravel()\n",
    "\n",
    "    # Create DataFrame with true and predicted labels\n",
    "    results = pd.DataFrame({\n",
    "        'True Labels': eval_labels,\n",
    "        'Predicted Labels': predictions\n",
    "    })\n",
    "\n",
    "    # Compute additional statistics\n",
    "    mse = np.mean((results['True Labels'] - results['Predicted Labels'])**2)\n",
    "    correlation = results.corr().iloc[0, 1]\n",
    "    r_squared = model.rsquared\n",
    "\n",
    "    # Return a summary as a dictionary\n",
    "    summary = {\n",
    "        \"R-squared\": r_squared,\n",
    "        \"MSE\": mse,\n",
    "        \"Correlation\": correlation\n",
    "    }\n",
    "\n",
    "    return results, summary, model\n",
    "\n",
    "def pipeline(dataframe):\n",
    "    # Takens in a pd dataframe with dependent variable as last collumn\n",
    "    train_features, train_labels, eval_features, eval_labels= split_for_training(dataframe = dataframe)\n",
    "    results, summary, model = linear_regression(train_features, train_labels, eval_features, eval_labels)\n",
    "    return results, summary, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a linear regression of entire embedding space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.056006</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>-0.074166</td>\n",
       "      <td>-0.038422</td>\n",
       "      <td>-0.032403</td>\n",
       "      <td>-0.052625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017435</td>\n",
       "      <td>-0.083821</td>\n",
       "      <td>0.018091</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>-0.032134</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.032137</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052798</td>\n",
       "      <td>0.075755</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>0.033089</td>\n",
       "      <td>-0.067629</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019186</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>-0.033818</td>\n",
       "      <td>-0.027357</td>\n",
       "      <td>-0.003923</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>-0.012395</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>-0.005835</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>-0.028901</td>\n",
       "      <td>-0.025120</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>-0.080185</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>-0.007302</td>\n",
       "      <td>0.063295</td>\n",
       "      <td>-0.006313</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014146</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>-0.015548</td>\n",
       "      <td>0.067399</td>\n",
       "      <td>-0.019534</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>-0.008207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060990</td>\n",
       "      <td>-0.053627</td>\n",
       "      <td>-0.004191</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>-0.044532</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>-0.025506</td>\n",
       "      <td>0.027986</td>\n",
       "      <td>-0.049235</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>-0.013070</td>\n",
       "      <td>-0.023716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013448</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.002915</td>\n",
       "      <td>-0.078581</td>\n",
       "      <td>-0.027976</td>\n",
       "      <td>0.051263</td>\n",
       "      <td>-0.015408</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.052332</td>\n",
       "      <td>-0.031843</td>\n",
       "      <td>0.058264</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>0.026583</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>0.030304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050849</td>\n",
       "      <td>-0.004629</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>-0.008960</td>\n",
       "      <td>-0.032014</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>-0.021354</td>\n",
       "      <td>-0.025655</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-0.013684</td>\n",
       "      <td>-0.004532</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>0.015303</td>\n",
       "      <td>-0.053443</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>-0.028368</td>\n",
       "      <td>-0.031292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045389</td>\n",
       "      <td>-0.037037</td>\n",
       "      <td>-0.017038</td>\n",
       "      <td>-0.024100</td>\n",
       "      <td>-0.039845</td>\n",
       "      <td>-0.008036</td>\n",
       "      <td>0.034701</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-0.009864</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>-0.048831</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>-0.011917</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>-0.109243</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>-0.062419</td>\n",
       "      <td>-0.007638</td>\n",
       "      <td>-0.003127</td>\n",
       "      <td>-0.059616</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>-0.006997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-0.038319</td>\n",
       "      <td>-0.030942</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.035778</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>-0.119782</td>\n",
       "      <td>-0.014108</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.051855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026296</td>\n",
       "      <td>0.070467</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.015341</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.042659</td>\n",
       "      <td>-0.012820</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-0.035251</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>-0.004969</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>-0.013780</td>\n",
       "      <td>0.023288</td>\n",
       "      <td>-0.059662</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>-0.040623</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044071</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>-0.008770</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>0.031415</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.000681  0.011969  0.007110  0.056006 -0.013802  0.002825 -0.074166   \n",
       "1     -0.052798  0.075755 -0.001987  0.000904 -0.011588  0.033089 -0.067629   \n",
       "2      0.009014  0.027232 -0.008476  0.004338 -0.005835  0.027945 -0.028901   \n",
       "3      0.014146 -0.014848  0.020604 -0.015548  0.067399 -0.019534  0.006101   \n",
       "4      0.017105  0.003651 -0.025506  0.027986 -0.049235  0.026457  0.001021   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  0.011085  0.052332 -0.031843  0.058264  0.027730 -0.017164  0.019456   \n",
       "99996 -0.013684 -0.004532 -0.000021  0.002012 -0.036970  0.015303 -0.053443   \n",
       "99997 -0.009864  0.062980 -0.004281  0.011968 -0.048831  0.009148 -0.011917   \n",
       "99998 -0.038319 -0.030942  0.000578  0.035778 -0.006674  0.025017 -0.119782   \n",
       "99999 -0.035251  0.002938 -0.004969 -0.021441 -0.013780  0.023288 -0.059662   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "0     -0.038422 -0.032403 -0.052625  ... -0.017435 -0.083821  0.018091   \n",
       "1      0.008990 -0.012016  0.013745  ... -0.019186  0.009903  0.021706   \n",
       "2     -0.025120 -0.059339  0.007081  ...  0.013033 -0.080185  0.032007   \n",
       "3     -0.036307 -0.044389 -0.008207  ...  0.060990 -0.053627 -0.004191   \n",
       "4      0.021197 -0.013070 -0.023716  ... -0.013448 -0.054813  0.036677   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99995  0.026583  0.028154  0.030304  ...  0.050849 -0.004629 -0.018710   \n",
       "99996  0.004630 -0.028368 -0.031292  ...  0.045389 -0.037037 -0.017038   \n",
       "99997  0.008560 -0.109243  0.008025  ...  0.044700 -0.062419 -0.007638   \n",
       "99998 -0.014108  0.009791  0.051855  ... -0.026296  0.070467  0.001978   \n",
       "99999  0.015152 -0.040623  0.025345  ...  0.044071  0.007150 -0.008770   \n",
       "\n",
       "            762       763       764       765       766       767  rating  \n",
       "0      0.004658  0.043822 -0.032134  0.011237  0.032137  0.002469       8  \n",
       "1     -0.033818 -0.027357 -0.003923  0.050545 -0.012395  0.008518       9  \n",
       "2     -0.007302  0.063295 -0.006313  0.012379  0.039789 -0.008009       3  \n",
       "3      0.001987 -0.044532  0.004179  0.011248  0.030314  0.010463       9  \n",
       "4     -0.000025 -0.002915 -0.078581 -0.027976  0.051263 -0.015408      10  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "99995 -0.008960 -0.032014  0.018132 -0.021354 -0.025655  0.001401       1  \n",
       "99996 -0.024100 -0.039845 -0.008036  0.034701  0.054411  0.004922      10  \n",
       "99997 -0.003127 -0.059616 -0.000292  0.032552  0.016399 -0.006997      10  \n",
       "99998 -0.017372 -0.015341  0.030835  0.042659 -0.012820  0.001306      10  \n",
       "99999 -0.000175  0.013621  0.031415  0.035716  0.045600  0.017061       9  \n",
       "\n",
       "[100000 rows x 769 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_corrected_embeddings.drop(columns=\"time_subspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only subspace Model:\n",
      "\n",
      "Summary of All Models:\n",
      "   R-squared       MSE  Correlation           Model Name\n",
      "0   0.011357  8.221192     0.115816  Only subspace Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7f80071fa9c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dictionary with model names and corresponding data\n",
    "model_data = {\n",
    "    \"Only subspace Model\" : time_corrected_embeddings.iloc[:,-2:]\n",
    "}\n",
    "\n",
    "# Initialize a list to store summaries\n",
    "summaries = []\n",
    "\n",
    "# Iterate through the dictionary\n",
    "for model_name, data in model_data.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    results, summary, model = pipeline(data)  # Assuming pipeline returns (results, summary, model)\n",
    "    # Add the model name to the summary dictionary and append to the list\n",
    "    summary[\"Model Name\"] = model_name\n",
    "    summaries.append(summary)\n",
    "    print(\"\")\n",
    "\n",
    "# Convert the list of summaries into a DataFrame\n",
    "summary_df = pd.DataFrame(summaries)\n",
    "\n",
    "# Display the combined summary\n",
    "print(\"Summary of All Models:\")\n",
    "print(summary_df)\n",
    "# Mini 0.453455     0.541113  \n",
    "\n",
    "train_features, train_labels, eval_features, eval_labels= split_for_training(dataframe = time_corrected_embeddings.drop(columns=\"time_subspace\"))\n",
    "results, summary, model = linear_regression(train_features, train_labels, eval_features, eval_labels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
