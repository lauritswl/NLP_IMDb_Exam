{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "# !pip install -r /work/NLP_IMDb_Exam/requirements.txt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "import evaluate\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict= {\n",
    "    1 :{\"name\" : \"Time_Vector\",\n",
    "        \"huggingface\" : \"sentence-transformers/all-mpnet-base-v2\",},\n",
    "    }\n",
    "# Choose a model for a pseudo-function\n",
    "Chosen_Model = 1\n",
    "\n",
    "data_path = f'../Data/MPNET_base/MPNET_base.csv'\n",
    "active_dataframe = pd.read_csv(data_path)\n",
    "embeddings = active_dataframe.iloc[:,0:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/MPNET_base/MPNET_base.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_to_negative_vector(Positive, Negative):\n",
    "    \"\"\"\n",
    "    Takes a positive and an negative data point and defines the vector spanning both vectors.\n",
    "    \"\"\"\n",
    "    posneg_vector = Positive.mean().to_frame().T-Negative.mean().to_frame().T\n",
    "    posneg_vector = pd.DataFrame(posneg_vector)\n",
    "    return posneg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11733, 768)\n",
      "(11733, 768)\n"
     ]
    }
   ],
   "source": [
    "# Define positive and negative average embeddings\n",
    "embeddings = active_dataframe.iloc[:,0:-3]\n",
    "positive = embeddings[active_dataframe['rating'] > 8] #positive ratings defined better ratings than 8 (9, 10)\n",
    "negative = embeddings[active_dataframe['rating'] < 3] #negative ratings defined as worse than 3 (1, 2)\n",
    "PosNeg_vector = positive_to_negative_vector(Positive = positive, Negative = negative)\n",
    "\n",
    "# Determine the minimum length\n",
    "min_length = min(len(positive), len(negative))\n",
    "\n",
    "# Truncate the longer dataframe\n",
    "positive = positive.iloc[:min_length]\n",
    "negative = negative.iloc[:min_length]\n",
    "\n",
    "print(positive.shape)\n",
    "print(negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_GPT_Reviews = np.array([\n",
    "    \"An innovative thriller with a fresh take on a classic trope. The visuals are stunning, and the narrative keeps you on edge.\",\n",
    "    \"A heartfelt drama that explores the complexities of modern relationships with a touch of humor.\",\n",
    "    \"A bold and ambitious project that pushes the boundaries of storytelling, even if it stumbles at times.\",\n",
    "    \"Packed with adrenaline-pumping action and a surprisingly emotional core.\",\n",
    "    \"A visually dazzling experience that occasionally prioritizes style over substance.\",\n",
    "    \"A poignant exploration of identity and belonging, delivered with wit and sensitivity.\",\n",
    "    \"An immersive world brought to life with groundbreaking effects and memorable performances.\",\n",
    "    \"A compelling mix of drama and suspense, though it falters in its final act.\",\n",
    "    \"A powerful meditation on grief and resilience, featuring standout performances.\",\n",
    "    \"An entertaining blend of comedy and drama that offers more depth than expected.\",\n",
    "    \"A fast-paced adventure that keeps you guessing until the very end.\",\n",
    "    \"A dark and gritty tale that subverts genre expectations with finesse.\",\n",
    "    \"A character-driven narrative that tugs at the heartstrings while offering profound insights.\",\n",
    "    \"A satirical comedy that doesnâ€™t shy away from tackling tough subjects with biting humor.\",\n",
    "    \"An emotionally charged story that explores the sacrifices made in pursuit of a dream.\",\n",
    "    \"A visually stunning piece with a hauntingly beautiful score.\",\n",
    "    \"A sharp and cleverly written script that keeps the audience engaged throughout.\",\n",
    "    \"A unique blend of genres that creates a truly unforgettable experience.\",\n",
    "    \"A gripping tale of survival with breathtaking cinematography.\",\n",
    "    \"A thoughtful exploration of morality wrapped in an intense thriller.\"\n",
    "])\n",
    "\n",
    "Negative_GPT_Reviews = np.array([\n",
    "    \"A timeless classic that set the standard for its genre, filled with unforgettable performances.\",\n",
    "    \"A groundbreaking work that influenced countless filmmakers and continues to inspire.\",\n",
    "    \"A charming story that captures the essence of a bygone era with grace and style.\",\n",
    "    \"A riveting drama that explores universal themes with remarkable depth.\",\n",
    "    \"An iconic performance that elevates a simple story into a masterpiece.\",\n",
    "    \"A visually striking film that pioneered techniques still in use today.\",\n",
    "    \"A poignant reflection on human nature, delivered with subtlety and nuance.\",\n",
    "    \"A thrilling tale that keeps audiences captivated from start to finish.\",\n",
    "    \"A beautifully crafted story that has stood the test of time.\",\n",
    "    \"An unforgettable musical score paired with stunning visuals makes this a true classic.\",\n",
    "    \"A deeply emotional narrative that resonates across generations.\",\n",
    "    \"A tale of love and sacrifice that remains relevant and touching.\",\n",
    "    \"A technically brilliant film that revolutionized the industry.\",\n",
    "    \"A cultural milestone that continues to influence popular culture.\",\n",
    "    \"A gripping story brought to life with stellar performances and masterful direction.\",\n",
    "    \"An inspiring story of hope and perseverance against all odds.\",\n",
    "    \"A daring and innovative film that broke new ground in its day.\",\n",
    "    \"A nostalgic journey into the golden age of cinema, filled with memorable moments.\",\n",
    "    \"A perfect balance of humor, drama, and heart that has enchanted audiences for decades.\",\n",
    "    \"A stunning achievement in storytelling, unmatched in its era.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5370f61f0e44f398f90a2ad6c23f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b362ac58d70140d8bddb851f9e9b5683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd66853e884d40d7b6706a6d2110ae7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d5265e8fa1471eba3beba9aa8f84a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522d6243c009449e864dd527fe0ea4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fc9bfb8b5b4e888c01145ab428e049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3e933c6455484c8968af952f326ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5c1debb7024334b087648ba9328fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5903b792d805414984543c4bd146adb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc125eddbf7e49ff91b9d26026a74198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0eb693b0b8439b9d4213e59b695593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015399</td>\n",
       "      <td>-0.010045</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.010337</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>-0.014409</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>0.01878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024741</td>\n",
       "      <td>-0.017696</td>\n",
       "      <td>-0.007649</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.01395</td>\n",
       "      <td>0.006252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.015399 -0.010045 -0.003328  0.002149 -0.010337  0.006522 -0.014409   \n",
       "\n",
       "      7         8        9    ...       758       759       760       761  \\\n",
       "0 -0.0059  0.011436  0.01878  ...  0.024741 -0.017696 -0.007649  0.001909   \n",
       "\n",
       "        762       763       764       765      766       767  \n",
       "0 -0.005377  0.006594  0.013565  0.003206  0.01395  0.006252  \n",
       "\n",
       "[1 rows x 768 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model = SentenceTransformer(model_dict[Chosen_Model][\"huggingface\"], device=\"cuda\") # Choose the best sentence transformer according to https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "Positive_GPT_Embeddings = pd.DataFrame(transformer_model.encode(Positive_GPT_Reviews))\n",
    "Negative_GPT_Embeddings = pd.DataFrame(transformer_model.encode(Negative_GPT_Reviews))\n",
    "PosNeg_GPT= positive_to_negative_vector(Positive= Positive_GPT_Embeddings, Negative= Negative_GPT_Embeddings)\n",
    "PosNeg_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_matrix_to_vector(matrix, vector):\n",
    "    \"\"\"Compute the projection of a matrix onto the space spanned by the vector\n",
    "    Args:\n",
    "        vector: ndarray of dimension (D, 1), the vector spanning D dimensions that you want to project upon.\n",
    "        matrix: ndarray of dimension (D, M), the matrix consisting of M vectors that you want to map to the subspace spanned by the vector.\n",
    "    \n",
    "    Returns:\n",
    "        p: projection of matrix onto the subspac spanned by the columns of vector; size (D, 1)\n",
    "    \"\"\"\n",
    "    m = matrix.to_numpy() # Turn into a matrix\n",
    "    v = vector.to_numpy()[0] #Turn into a numpy array\n",
    "\n",
    "    # Compute v dot v (denominator)\n",
    "    v_dot_v = np.dot(v, v)\n",
    "\n",
    "    # Compute projection of each row of m onto v\n",
    "    projection = np.outer(np.dot(m, v) / v_dot_v, v)\n",
    "    projection = pd.DataFrame(projection)\n",
    "\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def express_matrix_by_vector(matrix, vector):\n",
    "    \"\"\"Compute the projection of a matrix onto the space spanned by the vector\n",
    "    Args:\n",
    "        vector: ndarray of dimension (D, 1), the vector spanning D dimensions that you want to project upon.\n",
    "        matrix: ndarray of dimension (D, M), the matrix consisting of M vectors that you want to map to the subspace spanned by the vector.\n",
    "    \n",
    "    Returns:\n",
    "        projection: projection of matrix onto the subspac spanned by the columns of vector; size (D, 1)\n",
    "        projection_in_1D_subspace: Each embedding projected onto 1 dimensional subspace spanned by input vector.\n",
    "    \"\"\"\n",
    "    unit_vector = vector / np.linalg.norm(vector) # Find the unit vector for interpretatbility by dividing with its norm\n",
    "    projection = project_matrix_to_vector(matrix, vector) # Find projections, so we can find lengths by finding relations in first dimension\n",
    "    projection_in_1D_subspace = projection.iloc[:,0]/unit_vector.iloc[:,0][0] # Location in subspace\n",
    "\n",
    "    return projection, projection_in_1D_subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving outputs for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save GPT positive-negative corrected embedding:\n",
    "# Save positive negative corrected embedding:\n",
    "projected_variance, projection_in_1D_subspace = express_matrix_by_vector(matrix=embeddings, vector=PosNeg_GPT)\n",
    "# projected_variance = project_matrix_to_vector(matrix=embeddings, vector=posneg_vector)\n",
    "posneg_GPT_corrected_embeddings = pd.DataFrame(embeddings.to_numpy()-projected_variance.to_numpy())\n",
    "posneg_GPT_corrected_embeddings['posneg_subspace'] = projection_in_1D_subspace\n",
    "posneg_GPT_corrected_embeddings['rating'] = active_dataframe['rating']\n",
    "posneg_GPT_corrected_embeddings['average_rating'] = active_dataframe['average_rating']\n",
    "save_corrected = f'../Data/{model_dict[Chosen_Model][\"name\"]}/{model_dict[Chosen_Model][\"name\"]}_GPT_corrected.csv'\n",
    "posneg_GPT_corrected_embeddings.to_csv(save_corrected, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
